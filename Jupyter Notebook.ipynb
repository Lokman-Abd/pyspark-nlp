{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a53bf986",
   "metadata": {},
   "source": [
    "This Lab is Data Preprocessing Project\n",
    "\n",
    "## Lab sentiment analysis (NLP)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87df0f45",
   "metadata": {},
   "source": [
    "# Table of Contents \n",
    "<ol start=\"1\">\n",
    "<li> About the project</li>\n",
    "<li> Loading and Cleaning with Pandas</li>\n",
    "<li> Data cleaning </li>\n",
    "<li> Feature engineering </li>\n",
    "<li> Text Preprocessing </li>\n",
    "<li> build Model </li>\n",
    "<li> Visualization </li>\n",
    "<li> Conclusion </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08202e8b",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "The surge in MOOC learner reviews demands efficient data preprocessing for subsequent model readiness. Manual analysis is impractical due to the data volume. This project focuses on crucial preprocessing steps—cleaning, feature engineering, normalization, and transformation—to optimize the data for sentiment analysis models. The goal is to enable MOOC platforms to derive actionable insights, improve course quality, and identify areas for enhancement through systematic and effective data preparation. \n",
    "\n",
    "## Data Source\n",
    "Udemy Courses- Comments.csv- Kaggle: \"This dataset contains detailed information on all available Udemy courses on Oct 10, 2022. This data was provided in the \"Course_info.csv\" file. Also, over 9 million comments were collected and provided in the \"Comments.csv\" file. The information of over 209k courses was collected by web scraping the Udemy website. Udemy holds 209,734 courses and 73,514 instructors teaching courses in 79 languages in 13 different categories.\" --Kaggle.\n",
    "In this Project we only use Comments.csv."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4505ebdf",
   "metadata": {},
   "source": [
    "import appropriate libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ba7984d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np   # NumPy for numerical operations\n",
    "import pandas as pd  # Pandas for data manipulation\n",
    "from nltk.tokenize import word_tokenize  # NLTK for natural language processing - tokenization\n",
    "from nltk.corpus import stopwords  # NLTK for stop words\n",
    "from nltk.stem.lancaster import LancasterStemmer  # NLTK for stemming\n",
    "from nltk.stem.wordnet import WordNetLemmatizer  # NLTK for lemmatization\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  # Scikit-learn for TF-IDF vectorization\n",
    "from sklearn.model_selection import train_test_split  # Scikit-learn for train-test split\n",
    "from tqdm import tqdm  # tqdm for progress bars\n",
    "from bs4 import BeautifulSoup  # BeautifulSoup for HTML parsing\n",
    "\n",
    "\n",
    "# Importing emot library for emotion analysis\n",
    "# !pip install emot\n",
    "import emot \n",
    "\n",
    "# Regular expression library for text processing\n",
    "import re\n",
    "\n",
    "# Language detection library\n",
    "# !pip install langdetect\n",
    "from langdetect import detect\n",
    "\n",
    "# Translators library for language translation\n",
    "# !pip install translators\n",
    "import translators as ts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5365b0ff",
   "metadata": {},
   "source": [
    "###  Reading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "aa321d2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('Comments.csv')\n",
    "# get only 1000000 rows (from over 9,000,000 records)\n",
    "df=df.head(1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c7f7d9",
   "metadata": {},
   "source": [
    "### Inspecting and Performing Basic Operations on the \n",
    "check columns information with types and null values etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "181ed6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000000 entries, 0 to 999999\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count    Dtype  \n",
      "---  ------        --------------    -----  \n",
      " 0   id            1000000 non-null  int64  \n",
      " 1   course_id     1000000 non-null  int64  \n",
      " 2   rate          1000000 non-null  float64\n",
      " 3   date          1000000 non-null  object \n",
      " 4   display_name  999519 non-null   object \n",
      " 5   comment       999856 non-null   object \n",
      "dtypes: float64(1), int64(2), object(3)\n",
      "memory usage: 45.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f68f9b81",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>course_id</th>\n",
       "      <th>rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>1000000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.911845e+07</td>\n",
       "      <td>2.584639e+06</td>\n",
       "      <td>4.382235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.945712e+07</td>\n",
       "      <td>1.365302e+06</td>\n",
       "      <td>1.047236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.820000e+02</td>\n",
       "      <td>5.664000e+03</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.502647e+07</td>\n",
       "      <td>1.435326e+06</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.218722e+07</td>\n",
       "      <td>2.630370e+06</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.065253e+08</td>\n",
       "      <td>3.785872e+06</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.267090e+08</td>\n",
       "      <td>4.913148e+06</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     course_id            rate\n",
       "count  1.000000e+06  1.000000e+06  1000000.000000\n",
       "mean   6.911845e+07  2.584639e+06        4.382235\n",
       "std    3.945712e+07  1.365302e+06        1.047236\n",
       "min    2.820000e+02  5.664000e+03        0.500000\n",
       "25%    3.502647e+07  1.435326e+06        4.000000\n",
       "50%    7.218722e+07  2.630370e+06        5.000000\n",
       "75%    1.065253e+08  3.785872e+06        5.000000\n",
       "max    1.267090e+08  4.913148e+06        5.000000"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3589169d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>course_id</th>\n",
       "      <th>rate</th>\n",
       "      <th>date</th>\n",
       "      <th>display_name</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88962892</td>\n",
       "      <td>3173036</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-06-29T18:54:25-07:00</td>\n",
       "      <td>Rahul</td>\n",
       "      <td>I think a beginner needs more than you think.\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>125535470</td>\n",
       "      <td>4913148</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2022-10-07T11:17:41-07:00</td>\n",
       "      <td>Marlo</td>\n",
       "      <td>Aviva is such a natural teacher and healer/hea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68767147</td>\n",
       "      <td>3178386</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2020-10-19T06:35:37-07:00</td>\n",
       "      <td>Yamila Andrea</td>\n",
       "      <td>Muy buena la introducción para entender la bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>125029758</td>\n",
       "      <td>3175814</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2022-09-30T21:13:49-07:00</td>\n",
       "      <td>Jacqueline</td>\n",
       "      <td>This course is the best on Udemy.  This breakd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76584052</td>\n",
       "      <td>3174896</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2021-01-30T08:45:11-08:00</td>\n",
       "      <td>Anthony</td>\n",
       "      <td>I found this course very helpful. It was full ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  course_id  rate                       date   display_name  \\\n",
       "0   88962892    3173036   1.0  2021-06-29T18:54:25-07:00          Rahul   \n",
       "1  125535470    4913148   5.0  2022-10-07T11:17:41-07:00          Marlo   \n",
       "2   68767147    3178386   3.5  2020-10-19T06:35:37-07:00  Yamila Andrea   \n",
       "3  125029758    3175814   5.0  2022-09-30T21:13:49-07:00     Jacqueline   \n",
       "4   76584052    3174896   4.5  2021-01-30T08:45:11-08:00        Anthony   \n",
       "\n",
       "                                             comment  \n",
       "0  I think a beginner needs more than you think.\\...  \n",
       "1  Aviva is such a natural teacher and healer/hea...  \n",
       "2  Muy buena la introducción para entender la bas...  \n",
       "3  This course is the best on Udemy.  This breakd...  \n",
       "4  I found this course very helpful. It was full ...  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first 5 rows  from the DataFrame\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e9fce3b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>course_id</th>\n",
       "      <th>rate</th>\n",
       "      <th>date</th>\n",
       "      <th>display_name</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>146704</th>\n",
       "      <td>106269742</td>\n",
       "      <td>3188554</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2022-01-29T11:46:29-08:00</td>\n",
       "      <td>Troy</td>\n",
       "      <td>Relatable, encouraging, well laid out, convers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328693</th>\n",
       "      <td>79361144</td>\n",
       "      <td>3265854</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2021-03-05T13:41:59-08:00</td>\n",
       "      <td>Donna</td>\n",
       "      <td>Great information, quickly. Helps if you alrea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43905</th>\n",
       "      <td>92815376</td>\n",
       "      <td>4237450</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2021-08-13T09:05:40-07:00</td>\n",
       "      <td>Bicky</td>\n",
       "      <td>It was excellent course</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901213</th>\n",
       "      <td>40767162</td>\n",
       "      <td>1437626</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-11-24T23:12:15-08:00</td>\n",
       "      <td>Tanvi</td>\n",
       "      <td>The focus of this course is on formatting. The...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824064</th>\n",
       "      <td>47375716</td>\n",
       "      <td>2034308</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2020-03-15T23:17:07-07:00</td>\n",
       "      <td>Julio César</td>\n",
       "      <td>En general un buen curso, me sirvió para refor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  course_id  rate                       date display_name  \\\n",
       "146704  106269742    3188554   5.0  2022-01-29T11:46:29-08:00         Troy   \n",
       "328693   79361144    3265854   4.0  2021-03-05T13:41:59-08:00        Donna   \n",
       "43905    92815376    4237450   5.0  2021-08-13T09:05:40-07:00        Bicky   \n",
       "901213   40767162    1437626   1.0  2019-11-24T23:12:15-08:00        Tanvi   \n",
       "824064   47375716    2034308   4.5  2020-03-15T23:17:07-07:00  Julio César   \n",
       "\n",
       "                                                  comment  \n",
       "146704  Relatable, encouraging, well laid out, convers...  \n",
       "328693  Great information, quickly. Helps if you alrea...  \n",
       "43905                             It was excellent course  \n",
       "901213  The focus of this course is on formatting. The...  \n",
       "824064  En general un buen curso, me sirvió para refor...  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display a random sample of 5 rows from the DataFrame\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c64574b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 duplicate values in the dataset\n"
     ]
    }
   ],
   "source": [
    "# Checking and Printing the number of duplicate values\n",
    "dup_count = df.duplicated().sum()\n",
    "\n",
    "print(f\"There are {dup_count} duplicate values in the dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "fdc32c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n",
      "course_id\n",
      "rate\n",
      "date\n",
      "display_name\n",
      "comment\n"
     ]
    }
   ],
   "source": [
    "# Display the list of column names in the DataFrame\n",
    "for col in df.columns.to_list():\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "06e3f11e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                int64\n",
       "course_id         int64\n",
       "rate            float64\n",
       "date             object\n",
       "display_name     object\n",
       "comment          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes # Display the data types of each column in the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "942e638a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                0\n",
       "course_id         0\n",
       "rate              0\n",
       "date              0\n",
       "display_name    481\n",
       "comment         144\n",
       "dtype: int64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum() # Check the number of null values in each column of the DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1b3d90",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "### Manage features and remove unnecessary ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "18222ad9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert the 'date' column to datetime format using pandas\n",
    "df['date'] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8cfd923e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>course_id</th>\n",
       "      <th>rate</th>\n",
       "      <th>date</th>\n",
       "      <th>display_name</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88962892</td>\n",
       "      <td>3173036</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-06-29 18:54:25-07:00</td>\n",
       "      <td>Rahul</td>\n",
       "      <td>I think a beginner needs more than you think.\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>125535470</td>\n",
       "      <td>4913148</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2022-10-07 11:17:41-07:00</td>\n",
       "      <td>Marlo</td>\n",
       "      <td>Aviva is such a natural teacher and healer/hea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  course_id  rate                       date display_name  \\\n",
       "0   88962892    3173036   1.0  2021-06-29 18:54:25-07:00        Rahul   \n",
       "1  125535470    4913148   5.0  2022-10-07 11:17:41-07:00        Marlo   \n",
       "\n",
       "                                             comment  \n",
       "0  I think a beginner needs more than you think.\\...  \n",
       "1  Aviva is such a natural teacher and healer/hea...  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to check if the values of \"date\" column were converted to datetime format\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ef853252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with null values in the 'comment' column\n",
    "df=df.dropna(subset=['comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8ea46c27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                0\n",
       "course_id         0\n",
       "rate              0\n",
       "date              0\n",
       "display_name    480\n",
       "comment           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum() # Check the removal of null values in the comment column was successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "540edce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicate comments by id \n",
    "df=df.drop_duplicates(subset=['id'], keep='first')\n",
    "\n",
    "# drop the id, display_name and course_id columns because they're not needed anymore\n",
    "df=df.drop(['id','display_name','course_id'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a7050af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rate       999856\n",
       "date       999856\n",
       "comment    999856\n",
       "dtype: int64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count() # Check the removal of rows with duplicate comment fields and columns (id,display_name, course_id)  was successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ed91598a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function to determine if a comment contains only numbers, blanks, or special characters\n",
    "def contains_only_numbers_or_special_chars(comment):\n",
    "    # Remove special characters and spaces\n",
    "    cleaned_text = re.sub('\\W+', '',comment)\n",
    "    # Remove special numbers\n",
    "    cleaned_text =re.sub(r'\\d+', '', cleaned_text)\n",
    "    return cleaned_text.strip()==''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b323d1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply filter to remove comments with only numbers, blanks, or special characters (unmeaningful comments)\n",
    "df=df[~df['comment'].apply(contains_only_numbers_or_special_chars)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e4624120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rate</th>\n",
       "      <th>date</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-06-29 18:54:25-07:00</td>\n",
       "      <td>I think a beginner needs more than you think.\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2022-10-07 11:17:41-07:00</td>\n",
       "      <td>Aviva is such a natural teacher and healer/hea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.5</td>\n",
       "      <td>2020-10-19 06:35:37-07:00</td>\n",
       "      <td>Muy buena la introducción para entender la bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2022-09-30 21:13:49-07:00</td>\n",
       "      <td>This course is the best on Udemy.  This breakd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2021-01-30 08:45:11-08:00</td>\n",
       "      <td>I found this course very helpful. It was full ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997809</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2022-09-26 09:08:15-07:00</td>\n",
       "      <td>Bem teorico, porem interessante, da uma boa id...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997810</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2022-10-02 14:00:08-07:00</td>\n",
       "      <td>Muito bom para organizar as ideias antes de co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997811</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2019-12-05 23:38:32-08:00</td>\n",
       "      <td>Le cours est très bien mais certains exercices...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997812</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2019-12-11 21:19:14-08:00</td>\n",
       "      <td>C'est un cours ordonné, et stimulant. L'instru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997813</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2020-01-16 04:25:00-08:00</td>\n",
       "      <td>La formatrice explique très bien, et elle met ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>997814 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        rate                       date  \\\n",
       "0        1.0  2021-06-29 18:54:25-07:00   \n",
       "1        5.0  2022-10-07 11:17:41-07:00   \n",
       "2        3.5  2020-10-19 06:35:37-07:00   \n",
       "3        5.0  2022-09-30 21:13:49-07:00   \n",
       "4        4.5  2021-01-30 08:45:11-08:00   \n",
       "...      ...                        ...   \n",
       "997809   5.0  2022-09-26 09:08:15-07:00   \n",
       "997810   5.0  2022-10-02 14:00:08-07:00   \n",
       "997811   4.5  2019-12-05 23:38:32-08:00   \n",
       "997812   5.0  2019-12-11 21:19:14-08:00   \n",
       "997813   5.0  2020-01-16 04:25:00-08:00   \n",
       "\n",
       "                                                  comment  \n",
       "0       I think a beginner needs more than you think.\\...  \n",
       "1       Aviva is such a natural teacher and healer/hea...  \n",
       "2       Muy buena la introducción para entender la bas...  \n",
       "3       This course is the best on Udemy.  This breakd...  \n",
       "4       I found this course very helpful. It was full ...  \n",
       "...                                                   ...  \n",
       "997809  Bem teorico, porem interessante, da uma boa id...  \n",
       "997810  Muito bom para organizar as ideias antes de co...  \n",
       "997811  Le cours est très bien mais certains exercices...  \n",
       "997812  C'est un cours ordonné, et stimulant. L'instru...  \n",
       "997813  La formatrice explique très bien, et elle met ...  \n",
       "\n",
       "[997814 rows x 3 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reset index\n",
    "df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757ba1c5",
   "metadata": {},
   "source": [
    "### get a sample to work on with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "209d6fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rate</th>\n",
       "      <th>date</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>0.5</td>\n",
       "      <td>2020-07-30 17:47:36-07:00</td>\n",
       "      <td>ничего интересного я  на этом курсе не узнал....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.5</td>\n",
       "      <td>2021-01-28 18:05:20-08:00</td>\n",
       "      <td>I need my certificate.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417</th>\n",
       "      <td>0.5</td>\n",
       "      <td>2021-11-20 08:48:40-08:00</td>\n",
       "      <td>This is a very poor course dont this course. W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3538</th>\n",
       "      <td>0.5</td>\n",
       "      <td>2021-05-21 04:28:46-07:00</td>\n",
       "      <td>Is just a quiz without explanations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3742</th>\n",
       "      <td>0.5</td>\n",
       "      <td>2017-04-30 00:08:39-07:00</td>\n",
       "      <td>the voice of this instructor is absolutely not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2022-10-17 14:56:19-07:00</td>\n",
       "      <td>Awesome course</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2020-12-11 05:38:38-08:00</td>\n",
       "      <td>Kurs spełnił moje oczekiwania, zrozumiale prze...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2022-07-25 00:54:40-07:00</td>\n",
       "      <td>Wonderful. Today, for the first time I got cla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2020-11-23 22:37:33-08:00</td>\n",
       "      <td>this course vary help ful gand grate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2022-07-17 00:02:49-07:00</td>\n",
       "      <td>nice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      rate                       date  \\\n",
       "597    0.5  2020-07-30 17:47:36-07:00   \n",
       "997    0.5  2021-01-28 18:05:20-08:00   \n",
       "1417   0.5  2021-11-20 08:48:40-08:00   \n",
       "3538   0.5  2021-05-21 04:28:46-07:00   \n",
       "3742   0.5  2017-04-30 00:08:39-07:00   \n",
       "...    ...                        ...   \n",
       "1060   5.0  2022-10-17 14:56:19-07:00   \n",
       "1061   4.0  2020-12-11 05:38:38-08:00   \n",
       "1062   5.0  2022-07-25 00:54:40-07:00   \n",
       "1063   4.5  2020-11-23 22:37:33-08:00   \n",
       "1066   5.0  2022-07-17 00:02:49-07:00   \n",
       "\n",
       "                                                comment  \n",
       "597    ничего интересного я  на этом курсе не узнал....  \n",
       "997                              I need my certificate.  \n",
       "1417  This is a very poor course dont this course. W...  \n",
       "3538                Is just a quiz without explanations  \n",
       "3742  the voice of this instructor is absolutely not...  \n",
       "...                                                 ...  \n",
       "1060                                     Awesome course  \n",
       "1061  Kurs spełnił moje oczekiwania, zrozumiale prze...  \n",
       "1062  Wonderful. Today, for the first time I got cla...  \n",
       "1063               this course vary help ful gand grate  \n",
       "1066                                               nice  \n",
       "\n",
       "[4000 rows x 3 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate separate DataFrames based on rate conditions \n",
    "shape=800\n",
    "df_0_1 = df[(df['rate'] >= 0) & (df['rate'] < 1)].head(shape)\n",
    "df_1_2 = df[(df['rate'] >= 1) & (df['rate'] < 2)].head(shape)\n",
    "df_2_3 = df[(df['rate'] >= 2) & (df['rate'] < 3)].head(shape)\n",
    "df_3_4 = df[(df['rate'] >= 3) & (df['rate'] < 4)].head(shape)\n",
    "df_4_5 = df[(df['rate'] >= 4) & (df['rate'] <= 5)].head(shape)\n",
    "\n",
    "# Concatenate the DataFrames\n",
    "df = pd.concat([df_0_1, df_1_2, df_2_3,df_3_4, df_4_5])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe052968",
   "metadata": {},
   "source": [
    "# Feature engineering\n",
    "\n",
    "\n",
    "- add detected_language column for the comment \n",
    "- add sentiment column based on rate \n",
    "- translate the non english comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f4b9c4f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rate</th>\n",
       "      <th>date</th>\n",
       "      <th>comment</th>\n",
       "      <th>detected_language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>0.5</td>\n",
       "      <td>2020-07-30 17:47:36-07:00</td>\n",
       "      <td>ничего интересного я  на этом курсе не узнал....</td>\n",
       "      <td>ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.5</td>\n",
       "      <td>2021-01-28 18:05:20-08:00</td>\n",
       "      <td>I need my certificate.</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417</th>\n",
       "      <td>0.5</td>\n",
       "      <td>2021-11-20 08:48:40-08:00</td>\n",
       "      <td>This is a very poor course dont this course. W...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3538</th>\n",
       "      <td>0.5</td>\n",
       "      <td>2021-05-21 04:28:46-07:00</td>\n",
       "      <td>Is just a quiz without explanations</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3742</th>\n",
       "      <td>0.5</td>\n",
       "      <td>2017-04-30 00:08:39-07:00</td>\n",
       "      <td>the voice of this instructor is absolutely not...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2022-10-17 14:56:19-07:00</td>\n",
       "      <td>Awesome course</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2020-12-11 05:38:38-08:00</td>\n",
       "      <td>Kurs spełnił moje oczekiwania, zrozumiale prze...</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2022-07-25 00:54:40-07:00</td>\n",
       "      <td>Wonderful. Today, for the first time I got cla...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2020-11-23 22:37:33-08:00</td>\n",
       "      <td>this course vary help ful gand grate</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2022-07-17 00:02:49-07:00</td>\n",
       "      <td>nice</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      rate                       date  \\\n",
       "597    0.5  2020-07-30 17:47:36-07:00   \n",
       "997    0.5  2021-01-28 18:05:20-08:00   \n",
       "1417   0.5  2021-11-20 08:48:40-08:00   \n",
       "3538   0.5  2021-05-21 04:28:46-07:00   \n",
       "3742   0.5  2017-04-30 00:08:39-07:00   \n",
       "...    ...                        ...   \n",
       "1060   5.0  2022-10-17 14:56:19-07:00   \n",
       "1061   4.0  2020-12-11 05:38:38-08:00   \n",
       "1062   5.0  2022-07-25 00:54:40-07:00   \n",
       "1063   4.5  2020-11-23 22:37:33-08:00   \n",
       "1066   5.0  2022-07-17 00:02:49-07:00   \n",
       "\n",
       "                                                comment detected_language  \n",
       "597    ничего интересного я  на этом курсе не узнал....                ru  \n",
       "997                              I need my certificate.                en  \n",
       "1417  This is a very poor course dont this course. W...                en  \n",
       "3538                Is just a quiz without explanations                en  \n",
       "3742  the voice of this instructor is absolutely not...                en  \n",
       "...                                                 ...               ...  \n",
       "1060                                     Awesome course                en  \n",
       "1061  Kurs spełnił moje oczekiwania, zrozumiale prze...                pl  \n",
       "1062  Wonderful. Today, for the first time I got cla...                en  \n",
       "1063               this course vary help ful gand grate                en  \n",
       "1066                                               nice                pl  \n",
       "\n",
       "[4000 rows x 4 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to detect language (similar to the previous example)\n",
    "def detect_language(comment):\n",
    "    try:\n",
    "        return detect(str(comment))\n",
    "    except:\n",
    "        return 'undetermined'  # Handle cases where language detection fails\n",
    "\n",
    "df['detected_language'] = df['comment'].apply(detect_language)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ab573416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many language are not recognized\n",
    "df[df[\"detected_language\"]==\"undetermined\"].size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50112ba",
   "metadata": {},
   "source": [
    "### Translate the Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "c6aac6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  do not transalte english comments\n",
    "non_english_comments=df[(df['detected_language'] != 'en')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "04311042",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating Comments:   0%|                                                                   | 0/1509 [00:00<?, ?it/s]C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_11764\\1291251974.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  non_english_comments.at[index, 'cleaned_comment'] = ts.translate_text(row['comment'])\n",
      "Translating Comments: 100%|████████████████████████████████████████████████████████| 1509/1509 [13:47<00:00,  1.82it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for index, row in tqdm(non_english_comments.iterrows(), total=len(non_english_comments), desc=\"Translating Comments\"):\n",
    "    try:\n",
    "        non_english_comments.at[index, 'cleaned_comment'] = ts.translate_text(row['comment'])\n",
    "    except:\n",
    "        row['cleaned_comment'] = \"Error in translation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "2d06d781",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rate</th>\n",
       "      <th>date</th>\n",
       "      <th>comment</th>\n",
       "      <th>detected_language</th>\n",
       "      <th>cleaned_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>0.5</td>\n",
       "      <td>2020-07-30 17:47:36-07:00</td>\n",
       "      <td>ничего интересного я  на этом курсе не узнал....</td>\n",
       "      <td>ru</td>\n",
       "      <td>I didn't learn anything interesting in this co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16231</th>\n",
       "      <td>0.5</td>\n",
       "      <td>2017-08-29 11:38:38-07:00</td>\n",
       "      <td>Comprei um curso sobre um assunto e metade del...</td>\n",
       "      <td>pt</td>\n",
       "      <td>I bought a course on a subject and half of it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24220</th>\n",
       "      <td>0.5</td>\n",
       "      <td>2017-12-12 09:00:57-08:00</td>\n",
       "      <td>Habla extraño, aunque con eso no me meto, pero...</td>\n",
       "      <td>es</td>\n",
       "      <td>He talks strangely, although I don't mess with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34698</th>\n",
       "      <td>0.5</td>\n",
       "      <td>2016-05-10 12:39:18-07:00</td>\n",
       "      <td>dumb</td>\n",
       "      <td>fr</td>\n",
       "      <td>dumb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40702</th>\n",
       "      <td>0.5</td>\n",
       "      <td>2018-03-19 12:59:01-07:00</td>\n",
       "      <td>More explanation</td>\n",
       "      <td>fr</td>\n",
       "      <td>More explanation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2022-02-10 07:26:04-08:00</td>\n",
       "      <td>Très bonne formation, complète et simple à sui...</td>\n",
       "      <td>fr</td>\n",
       "      <td>Very good training, complete and simple to fol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2022-09-14 23:46:37-07:00</td>\n",
       "      <td>Olá, Sue. Achei o curso bom. Atualizei a sua n...</td>\n",
       "      <td>pt</td>\n",
       "      <td>Hello, Sue. I thought the course was good. I'v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2021-08-27 09:00:40-07:00</td>\n",
       "      <td>Es sind sehr gute Anregungenn dabei. Danke.</td>\n",
       "      <td>de</td>\n",
       "      <td>There are very good suggestions. Thank you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2020-12-11 05:38:38-08:00</td>\n",
       "      <td>Kurs spełnił moje oczekiwania, zrozumiale prze...</td>\n",
       "      <td>pl</td>\n",
       "      <td>The course met my expectations, comprehensible...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2022-07-17 00:02:49-07:00</td>\n",
       "      <td>nice</td>\n",
       "      <td>pl</td>\n",
       "      <td>nice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1509 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       rate                       date  \\\n",
       "597     0.5  2020-07-30 17:47:36-07:00   \n",
       "16231   0.5  2017-08-29 11:38:38-07:00   \n",
       "24220   0.5  2017-12-12 09:00:57-08:00   \n",
       "34698   0.5  2016-05-10 12:39:18-07:00   \n",
       "40702   0.5  2018-03-19 12:59:01-07:00   \n",
       "...     ...                        ...   \n",
       "1048    5.0  2022-02-10 07:26:04-08:00   \n",
       "1050    5.0  2022-09-14 23:46:37-07:00   \n",
       "1052    5.0  2021-08-27 09:00:40-07:00   \n",
       "1061    4.0  2020-12-11 05:38:38-08:00   \n",
       "1066    5.0  2022-07-17 00:02:49-07:00   \n",
       "\n",
       "                                                 comment detected_language  \\\n",
       "597     ничего интересного я  на этом курсе не узнал....                ru   \n",
       "16231  Comprei um curso sobre um assunto e metade del...                pt   \n",
       "24220  Habla extraño, aunque con eso no me meto, pero...                es   \n",
       "34698                                               dumb                fr   \n",
       "40702                                   More explanation                fr   \n",
       "...                                                  ...               ...   \n",
       "1048   Très bonne formation, complète et simple à sui...                fr   \n",
       "1050   Olá, Sue. Achei o curso bom. Atualizei a sua n...                pt   \n",
       "1052         Es sind sehr gute Anregungenn dabei. Danke.                de   \n",
       "1061   Kurs spełnił moje oczekiwania, zrozumiale prze...                pl   \n",
       "1066                                                nice                pl   \n",
       "\n",
       "                                         cleaned_comment  \n",
       "597    I didn't learn anything interesting in this co...  \n",
       "16231  I bought a course on a subject and half of it ...  \n",
       "24220  He talks strangely, although I don't mess with...  \n",
       "34698                                               dumb  \n",
       "40702                                   More explanation  \n",
       "...                                                  ...  \n",
       "1048   Very good training, complete and simple to fol...  \n",
       "1050   Hello, Sue. I thought the course was good. I'v...  \n",
       "1052         There are very good suggestions. Thank you.  \n",
       "1061   The course met my expectations, comprehensible...  \n",
       "1066                                                nice  \n",
       "\n",
       "[1509 rows x 5 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_english_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "8738d394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors number : 0\n"
     ]
    }
   ],
   "source": [
    "# how many errors at translation\n",
    "print(f\"Errors number : {len(non_english_comments[non_english_comments['cleaned_comment'] == 'Error in translation'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "43f923c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rate</th>\n",
       "      <th>date</th>\n",
       "      <th>comment</th>\n",
       "      <th>detected_language</th>\n",
       "      <th>cleaned_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>0.5</td>\n",
       "      <td>2020-07-30 17:47:36-07:00</td>\n",
       "      <td>ничего интересного я  на этом курсе не узнал....</td>\n",
       "      <td>ru</td>\n",
       "      <td>I didn't learn anything interesting in this co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.5</td>\n",
       "      <td>2021-01-28 18:05:20-08:00</td>\n",
       "      <td>I need my certificate.</td>\n",
       "      <td>en</td>\n",
       "      <td>I need my certificate.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417</th>\n",
       "      <td>0.5</td>\n",
       "      <td>2021-11-20 08:48:40-08:00</td>\n",
       "      <td>This is a very poor course dont this course. W...</td>\n",
       "      <td>en</td>\n",
       "      <td>This is a very poor course dont this course. W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3538</th>\n",
       "      <td>0.5</td>\n",
       "      <td>2021-05-21 04:28:46-07:00</td>\n",
       "      <td>Is just a quiz without explanations</td>\n",
       "      <td>en</td>\n",
       "      <td>Is just a quiz without explanations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3742</th>\n",
       "      <td>0.5</td>\n",
       "      <td>2017-04-30 00:08:39-07:00</td>\n",
       "      <td>the voice of this instructor is absolutely not...</td>\n",
       "      <td>en</td>\n",
       "      <td>the voice of this instructor is absolutely not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2022-10-17 14:56:19-07:00</td>\n",
       "      <td>Awesome course</td>\n",
       "      <td>en</td>\n",
       "      <td>Awesome course</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2020-12-11 05:38:38-08:00</td>\n",
       "      <td>Kurs spełnił moje oczekiwania, zrozumiale prze...</td>\n",
       "      <td>pl</td>\n",
       "      <td>The course met my expectations, comprehensible...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2022-07-25 00:54:40-07:00</td>\n",
       "      <td>Wonderful. Today, for the first time I got cla...</td>\n",
       "      <td>en</td>\n",
       "      <td>Wonderful. Today, for the first time I got cla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2020-11-23 22:37:33-08:00</td>\n",
       "      <td>this course vary help ful gand grate</td>\n",
       "      <td>en</td>\n",
       "      <td>this course vary help ful gand grate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2022-07-17 00:02:49-07:00</td>\n",
       "      <td>nice</td>\n",
       "      <td>pl</td>\n",
       "      <td>nice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      rate                       date  \\\n",
       "597    0.5  2020-07-30 17:47:36-07:00   \n",
       "997    0.5  2021-01-28 18:05:20-08:00   \n",
       "1417   0.5  2021-11-20 08:48:40-08:00   \n",
       "3538   0.5  2021-05-21 04:28:46-07:00   \n",
       "3742   0.5  2017-04-30 00:08:39-07:00   \n",
       "...    ...                        ...   \n",
       "1060   5.0  2022-10-17 14:56:19-07:00   \n",
       "1061   4.0  2020-12-11 05:38:38-08:00   \n",
       "1062   5.0  2022-07-25 00:54:40-07:00   \n",
       "1063   4.5  2020-11-23 22:37:33-08:00   \n",
       "1066   5.0  2022-07-17 00:02:49-07:00   \n",
       "\n",
       "                                                comment detected_language  \\\n",
       "597    ничего интересного я  на этом курсе не узнал....                ru   \n",
       "997                              I need my certificate.                en   \n",
       "1417  This is a very poor course dont this course. W...                en   \n",
       "3538                Is just a quiz without explanations                en   \n",
       "3742  the voice of this instructor is absolutely not...                en   \n",
       "...                                                 ...               ...   \n",
       "1060                                     Awesome course                en   \n",
       "1061  Kurs spełnił moje oczekiwania, zrozumiale prze...                pl   \n",
       "1062  Wonderful. Today, for the first time I got cla...                en   \n",
       "1063               this course vary help ful gand grate                en   \n",
       "1066                                               nice                pl   \n",
       "\n",
       "                                        cleaned_comment  \n",
       "597   I didn't learn anything interesting in this co...  \n",
       "997                              I need my certificate.  \n",
       "1417  This is a very poor course dont this course. W...  \n",
       "3538                Is just a quiz without explanations  \n",
       "3742  the voice of this instructor is absolutely not...  \n",
       "...                                                 ...  \n",
       "1060                                     Awesome course  \n",
       "1061  The course met my expectations, comprehensible...  \n",
       "1062  Wonderful. Today, for the first time I got cla...  \n",
       "1063               this course vary help ful gand grate  \n",
       "1066                                               nice  \n",
       "\n",
       "[4000 rows x 5 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create new column cleaned comment to use just after\n",
    "df['cleaned_comment']=df['comment']\n",
    "# mergre non_english_comments to origin df \n",
    "df.update(non_english_comments)\n",
    "# remove the cooemnt with error in translation\n",
    "df = df[df['cleaned_comment'] != \"Error in translation\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "8d4c0131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set for each comment a sentiment based on rate\n",
    "for index, row in df.iterrows():\n",
    "    rate = row['rate']\n",
    "    if rate < 2:\n",
    "        df.at[index, 'sentiment'] = 'negative'\n",
    "    elif 2 <= rate <=3:\n",
    "        df.at[index, 'sentiment'] = 'neutral'\n",
    "    else:\n",
    "        df.at[index, 'sentiment'] = 'positive'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc55902f",
   "metadata": {},
   "source": [
    "# Text Preprocessing \n",
    "-  convert emoji and emoticon into words\n",
    "-  convert conments to lower case\n",
    "-  remove links using regular expressions\n",
    "-  remove HTML tags\n",
    "-  remove_numbers_or_special_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "5ae3e811",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  convert emoji and emoticon into words\n",
    "emot_obj = emot.core.emot() \n",
    "def replace_emojis_with_meanings(text):\n",
    "    emojis = emot_obj.emoji(text)['value']\n",
    "    emojis_meanings =  emot_obj.emoji(text)['mean']\n",
    "    emoticons = emot_obj.emoticons(text)['value']\n",
    "    emoticons_meanings =  emot_obj.emoticons(text)['mean']\n",
    "\n",
    "    # Remove special characters from meanings list\n",
    "    emojis_meanings = [re.sub(r'[^\\w\\s]', '', meaning) for meaning in emojis_meanings]\n",
    "     # Remove special characters from meanings list\n",
    "    emoticons_meanings = [re.sub(r'[^\\w\\s]', '', meaning) for meaning in emoticons_meanings]\n",
    "\n",
    "    # Replace emojis in the text with the corresponding meanings\n",
    "    for emoji, meaning in zip(emojis, emojis_meanings):\n",
    "        text = text.replace(emoji, meaning)\n",
    "    \n",
    "     # Replace emojis in the text with the corresponding meanings\n",
    "    for emoji, meaning in zip(emoticons, emoticons_meanings):\n",
    "        text = text.replace(emoji, meaning)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "499d1cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert conments to lower case\n",
    "def convert_to_lower(comment):\n",
    "    return comment.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "05311940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove links using regular expressions\n",
    "def remove_links(comment):\n",
    "    # Regular expression pattern to match URLs\n",
    "    pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "    return re.sub(pattern, '', comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "35f47ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove HTML tags\n",
    "def remove_html_tags(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    # Get the text without HTML tags\n",
    "    text_without_tags = soup.get_text(separator=\" \", strip=True)\n",
    "    return text_without_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "967723b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove_numbers_or_special_chars\n",
    "def remove_numbers_or_special_chars(comment):\n",
    "     # Replace escape sequences with an empty string\n",
    "    cleaned_text = re.sub(r'\\\\[^\\s]', ' ', comment)\n",
    "    # convert n't into not EX(didn't => did not)\n",
    "    cleaned_text= cleaned_text.replace(\"n't\", \" not\")\n",
    "    cleaned_text= cleaned_text.replace(\"_\", \" \")\n",
    "    # Remove special characters and spaces\n",
    "    cleaned_text = re.sub('\\W+', ' ',cleaned_text)    \n",
    "    # Remove special numbers\n",
    "    cleaned_text =re.sub(r'\\d+', ' ', cleaned_text)\n",
    "    return cleaned_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "06fc2271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply cleaning functions on comments\n",
    "def clean_text(comment):\n",
    "    text_res = replace_emojis_with_meanings(comment)\n",
    "    text_res = convert_to_lower(text_res)\n",
    "    text_res = remove_links(text_res)\n",
    "    text_res = remove_html_tags(text_res)\n",
    "    text_res = remove_numbers_or_special_chars(text_res)\n",
    "    return text_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "bc13382b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_11764\\3605553724.py:3: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(text, \"html.parser\")\n"
     ]
    }
   ],
   "source": [
    "df['cleaned_comment'] = df['cleaned_comment'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad297edc",
   "metadata": {},
   "source": [
    "## Tokanization , lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c5623060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stop words and lemmatization\n",
    "stop_words = set(stopwords.words('english'))\n",
    "# Words to keep\n",
    "\n",
    "words_to_keep = {'very','too','so','not','no','but'}\n",
    "# keep words like \"very\", and \"so\"\n",
    "stop_words = {word for word in stop_words if  word not in words_to_keep}\n",
    " \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(comment):\n",
    "    try:\n",
    "        tokens = word_tokenize(comment.lower())  # Tokenization\n",
    "        tokens = [token for token in tokens if token.isalpha()]  # Remove non-alphabetic tokens\n",
    "        tokens = [token for token in tokens if token not in stop_words]  # Remove stop words\n",
    "        tokens = [lemmatizer.lemmatize(token) for token in tokens]  # Lemmatization\n",
    "        return ' '.join(tokens)\n",
    "    except:\n",
    "        print(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "292bcadc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rate</th>\n",
       "      <th>date</th>\n",
       "      <th>comment</th>\n",
       "      <th>detected_language</th>\n",
       "      <th>cleaned_comment</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>0.5</td>\n",
       "      <td>2020-07-30 17:47:36-07:00</td>\n",
       "      <td>ничего интересного я  на этом курсе не узнал....</td>\n",
       "      <td>ru</td>\n",
       "      <td>i did not learn anything interesting in this c...</td>\n",
       "      <td>negative</td>\n",
       "      <td>not learn anything interesting course</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.5</td>\n",
       "      <td>2021-01-28 18:05:20-08:00</td>\n",
       "      <td>I need my certificate.</td>\n",
       "      <td>en</td>\n",
       "      <td>i need my certificate</td>\n",
       "      <td>negative</td>\n",
       "      <td>need certificate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417</th>\n",
       "      <td>0.5</td>\n",
       "      <td>2021-11-20 08:48:40-08:00</td>\n",
       "      <td>This is a very poor course dont this course. W...</td>\n",
       "      <td>en</td>\n",
       "      <td>this is a very poor course dont this course wa...</td>\n",
       "      <td>negative</td>\n",
       "      <td>very poor course dont course waste time money</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3538</th>\n",
       "      <td>0.5</td>\n",
       "      <td>2021-05-21 04:28:46-07:00</td>\n",
       "      <td>Is just a quiz without explanations</td>\n",
       "      <td>en</td>\n",
       "      <td>is just a quiz without explanations</td>\n",
       "      <td>negative</td>\n",
       "      <td>quiz without explanation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3742</th>\n",
       "      <td>0.5</td>\n",
       "      <td>2017-04-30 00:08:39-07:00</td>\n",
       "      <td>the voice of this instructor is absolutely not...</td>\n",
       "      <td>en</td>\n",
       "      <td>the voice of this instructor is absolutely not...</td>\n",
       "      <td>negative</td>\n",
       "      <td>voice instructor absolutely not clear very har...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2022-10-17 14:56:19-07:00</td>\n",
       "      <td>Awesome course</td>\n",
       "      <td>en</td>\n",
       "      <td>awesome course</td>\n",
       "      <td>positive</td>\n",
       "      <td>awesome course</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2020-12-11 05:38:38-08:00</td>\n",
       "      <td>Kurs spełnił moje oczekiwania, zrozumiale prze...</td>\n",
       "      <td>pl</td>\n",
       "      <td>the course met my expectations comprehensible ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>course met expectation comprehensible knowledg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2022-07-25 00:54:40-07:00</td>\n",
       "      <td>Wonderful. Today, for the first time I got cla...</td>\n",
       "      <td>en</td>\n",
       "      <td>wonderful today for the first time i got clari...</td>\n",
       "      <td>positive</td>\n",
       "      <td>wonderful today first time got clarity formula...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2020-11-23 22:37:33-08:00</td>\n",
       "      <td>this course vary help ful gand grate</td>\n",
       "      <td>en</td>\n",
       "      <td>this course vary help ful gand grate</td>\n",
       "      <td>positive</td>\n",
       "      <td>course vary help ful gand grate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2022-07-17 00:02:49-07:00</td>\n",
       "      <td>nice</td>\n",
       "      <td>pl</td>\n",
       "      <td>nice</td>\n",
       "      <td>positive</td>\n",
       "      <td>nice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      rate                       date  \\\n",
       "597    0.5  2020-07-30 17:47:36-07:00   \n",
       "997    0.5  2021-01-28 18:05:20-08:00   \n",
       "1417   0.5  2021-11-20 08:48:40-08:00   \n",
       "3538   0.5  2021-05-21 04:28:46-07:00   \n",
       "3742   0.5  2017-04-30 00:08:39-07:00   \n",
       "...    ...                        ...   \n",
       "1060   5.0  2022-10-17 14:56:19-07:00   \n",
       "1061   4.0  2020-12-11 05:38:38-08:00   \n",
       "1062   5.0  2022-07-25 00:54:40-07:00   \n",
       "1063   4.5  2020-11-23 22:37:33-08:00   \n",
       "1066   5.0  2022-07-17 00:02:49-07:00   \n",
       "\n",
       "                                                comment detected_language  \\\n",
       "597    ничего интересного я  на этом курсе не узнал....                ru   \n",
       "997                              I need my certificate.                en   \n",
       "1417  This is a very poor course dont this course. W...                en   \n",
       "3538                Is just a quiz without explanations                en   \n",
       "3742  the voice of this instructor is absolutely not...                en   \n",
       "...                                                 ...               ...   \n",
       "1060                                     Awesome course                en   \n",
       "1061  Kurs spełnił moje oczekiwania, zrozumiale prze...                pl   \n",
       "1062  Wonderful. Today, for the first time I got cla...                en   \n",
       "1063               this course vary help ful gand grate                en   \n",
       "1066                                               nice                pl   \n",
       "\n",
       "                                        cleaned_comment sentiment  \\\n",
       "597   i did not learn anything interesting in this c...  negative   \n",
       "997                              i need my certificate   negative   \n",
       "1417  this is a very poor course dont this course wa...  negative   \n",
       "3538                is just a quiz without explanations  negative   \n",
       "3742  the voice of this instructor is absolutely not...  negative   \n",
       "...                                                 ...       ...   \n",
       "1060                                     awesome course  positive   \n",
       "1061  the course met my expectations comprehensible ...  positive   \n",
       "1062  wonderful today for the first time i got clari...  positive   \n",
       "1063               this course vary help ful gand grate  positive   \n",
       "1066                                               nice  positive   \n",
       "\n",
       "                                             clean_text  \n",
       "597               not learn anything interesting course  \n",
       "997                                    need certificate  \n",
       "1417      very poor course dont course waste time money  \n",
       "3538                           quiz without explanation  \n",
       "3742  voice instructor absolutely not clear very har...  \n",
       "...                                                 ...  \n",
       "1060                                     awesome course  \n",
       "1061  course met expectation comprehensible knowledg...  \n",
       "1062  wonderful today first time got clarity formula...  \n",
       "1063                    course vary help ful gand grate  \n",
       "1066                                               nice  \n",
       "\n",
       "[4000 rows x 7 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_text'] = df['cleaned_comment'].apply(preprocess_text)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a2954d",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d8c621",
   "metadata": {},
   "source": [
    "### use tfidf for Text encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "b6cf6c83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.8998\n",
      "Testing Accuracy: 0.8967\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['clean_text'], df['sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Define a pipeline with TF-IDF vectorizer and Logistic Regression classifier\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features=5000,ngram_range=(1, 2))),\n",
    "    ('classifier', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(X_train)\n",
    "y_test_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Testing Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "4031ca47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted pos sentiment: ['positive']\n",
      "predicted net sentiment: ['neutral']\n",
      "predicted neg sentiment: ['negative']\n"
     ]
    }
   ],
   "source": [
    "# Make prediction using our trained model\n",
    "predicted_pos_sentiment = pipeline.predict([\"i did like it\"])\n",
    "predicted_net_sentiment = pipeline.predict([\"it is not bad but it is not good also\"])\n",
    "predicted_neg_sentiment = pipeline.predict([\"did not love it\"])\n",
    "\n",
    "print(f\"predicted pos sentiment: {predicted_pos_sentiment}\")\n",
    "print(f\"predicted net sentiment: {predicted_net_sentiment}\")\n",
    "print(f\"predicted neg sentiment: {predicted_neg_sentiment}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d4d654",
   "metadata": {},
   "source": [
    "### another Model with  word embedding Text encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "7e3f74b9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating vectors: 100%|████████████████████████████████████████████████████████████| 4000/4000 [00:54<00:00, 73.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.5603\n",
      "Testing Accuracy: 0.5413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load the spaCy model with word embeddings (e.g., en_core_web_md for medium-sized embeddings)\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Extract word embeddings for each document\n",
    "\n",
    "texts = df['clean_text']\n",
    "\n",
    "# Define the maximum length for padding\n",
    "max_length = 400\n",
    "\n",
    "# Calculate the fixed-size vectors for each document\n",
    "X = np.array([np.pad(nlp(text).vector, (0, max_length - len(nlp(text).vector)))[:max_length] for text in tqdm(texts, desc=\"Creating vectors\")])\n",
    "y = df['sentiment']\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define a pipeline with Logistic Regression classifier\n",
    "pipeline = Pipeline([\n",
    "    ('classifier', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = pipeline.predict(X_train)\n",
    "y_test_pred = pipeline.predict(X_test)\n",
    "\n",
    "# # Calculate accuracy\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Testing Accuracy: {test_accuracy:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "a927fb2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Sentiment: negative\n"
     ]
    }
   ],
   "source": [
    "# New text for sentiment prediction\n",
    "new_text = \"it was a very good course\"\n",
    "\n",
    "# Vectorize the new text\n",
    "new_text_vector = np.pad(nlp(new_text).vector, (0, max_length - len(nlp(new_text).vector)))[:max_length].reshape(1, -1)\n",
    "\n",
    "# Make predictions using the trained model\n",
    "predicted_sentiment = pipeline.predict(new_text_vector)\n",
    "\n",
    "print(f\"Predicted Sentiment: {predicted_sentiment[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "3ff680d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted pos sentiment: negative\n",
      "predicted net sentiment: negative\n",
      "predicted neg sentiment: negative\n"
     ]
    }
   ],
   "source": [
    "# Make prediction using your trained model\n",
    "pos_sentiment = \"i did liked it \"\n",
    "net_sentiment = \"it is not bad but it is not good also\"\n",
    "neg_sentiment = \"i did not love it \"\n",
    "\n",
    "# Vectorize the new text\n",
    "pos_sentiment_vector = np.pad(nlp(pos_sentiment).vector, (0, max_length - len(nlp(pos_sentiment).vector)))[:max_length].reshape(1, -1)\n",
    "net_sentiment_vector = np.pad(nlp(net_sentiment).vector, (0, max_length - len(nlp(net_sentiment).vector)))[:max_length].reshape(1, -1)\n",
    "neg_sentiment_vector = np.pad(nlp(neg_sentiment).vector, (0, max_length - len(nlp(neg_sentiment).vector)))[:max_length].reshape(1, -1)\n",
    "\n",
    "# Make predictions using the trained model\n",
    "predicted_pos_sentiment = pipeline.predict(pos_sentiment_vector)\n",
    "predicted_net_sentiment = pipeline.predict(net_sentiment_vector)\n",
    "predicted_neg_sentiment = pipeline.predict(neg_sentiment_vector)\n",
    "\n",
    "print(f\"predicted pos sentiment: {predicted_pos_sentiment[0]}\")\n",
    "print(f\"predicted net sentiment: {predicted_net_sentiment[0]}\")\n",
    "print(f\"predicted neg sentiment: {predicted_neg_sentiment[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "ad27a0a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 96 features, but LogisticRegression is expecting 400 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[153], line 16\u001b[0m\n\u001b[0;32m     12\u001b[0m predicted_neg_sentiment \u001b[38;5;241m=\u001b[39m [nlp(text)\u001b[38;5;241m.\u001b[39mvector \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m neg_sentiment]\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Use the trained model to predict sentiment\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredicted pos sentiment: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpipeline\u001b[38;5;241m.\u001b[39mpredict(predicted_pos_sentiment)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredicted net sentiment: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpipeline\u001b[38;5;241m.\u001b[39mpredict(predicted_net_sentiment)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredicted neg sentiment: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpipeline\u001b[38;5;241m.\u001b[39mpredict(predicted_neg_sentiment)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py:508\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[1;34m(self, X, **predict_params)\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(with_final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    507\u001b[0m     Xt \u001b[38;5;241m=\u001b[39m transform\u001b[38;5;241m.\u001b[39mtransform(Xt)\n\u001b[1;32m--> 508\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpredict(Xt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpredict_params)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:451\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    438\u001b[0m \u001b[38;5;124;03mPredict class labels for samples in X.\u001b[39;00m\n\u001b[0;32m    439\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;124;03m    Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    450\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m--> 451\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_function(X)\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    453\u001b[0m     indices \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(scores \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:432\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    429\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    430\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m--> 432\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    433\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39mreshape(scores, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)) \u001b[38;5;28;01mif\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m scores\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:625\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    622\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 625\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_n_features(X, reset\u001b[38;5;241m=\u001b[39mreset)\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:414\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    413\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    415\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    416\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    417\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 96 features, but LogisticRegression is expecting 400 features as input."
     ]
    }
   ],
   "source": [
    "\n",
    "# Make prediction using your trained model\n",
    "pos_sentiment = [\"i did liked it \"]\n",
    "net_sentiment = [\"it is not bad but it is not good also\"]\n",
    "neg_sentiment = [\"i did not love it \"]\n",
    "\n",
    "\n",
    "# Get the spaCy word embeddings for the new text\n",
    "predicted_pos_sentiment = [nlp(text).vector for text in pos_sentiment]\n",
    "# Get the spaCy word embeddings for the new text\n",
    "predicted_net_sentiment = [nlp(text).vector for text in net_sentiment]\n",
    "# Get the spaCy word embeddings for the new text\n",
    "predicted_neg_sentiment = [nlp(text).vector for text in neg_sentiment]\n",
    "\n",
    "# Use the trained model to predict sentiment\n",
    "\n",
    "print(f\"predicted pos sentiment: {pipeline.predict(predicted_pos_sentiment)}\")\n",
    "print(f\"predicted net sentiment: {pipeline.predict(predicted_net_sentiment)}\")\n",
    "print(f\"predicted neg sentiment: {pipeline.predict(predicted_neg_sentiment)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ba2ba7",
   "metadata": {},
   "source": [
    "# use extern Model to testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe315e24",
   "metadata": {},
   "source": [
    "### Roberta Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc5e4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e289cd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained (MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained (MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe77a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polarity_scores_roberta (text):\n",
    "    encoded_text = tokenizer (text, return_tensors= 'pt')\n",
    "    output = model(**encoded_text)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax (scores)\n",
    "    scores_dict ={\n",
    "    'roberta_neg':scores [0],\n",
    "    'roberta_neu':scores [1],\n",
    "    'roberta_pos':scores [2]\n",
    "    }\n",
    "    return scores_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9eb442a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for Roberta Model\n",
    "polarity_scores_roberta(df.iloc[40]['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8044d1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {}\n",
    "for index, row in tqdm(df.iterrows(),total=len(df), desc=\"Translating Comments\"):\n",
    "    text = row['clean_text']\n",
    "    try:\n",
    "        res[index] = polarity_scores_roberta(text)\n",
    "    except:\n",
    "        res[index]={}\n",
    "        print(f\"error in index {index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c7e43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(res).T\n",
    "# # Merge DataFrames based on index\n",
    "merged_df = pd.merge(df,res ,left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea95aee6",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020fe391",
   "metadata": {},
   "source": [
    "### word cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f2c3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "plt.figure(figsize = (20,20))\n",
    "wc = WordCloud(max_words = 200 , width = 1600 , height = 800,\n",
    "               collocations=False).generate(\" \".join(df[df['sentiment']==\"positive\"]['cleaned_comment']))\n",
    "plt.imshow(wc)\n",
    "plt.title(\"Most used words in positive comments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae63af7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "plt.figure(figsize = (20,20))\n",
    "wc = WordCloud(max_words = 200 , width = 1600 , height = 800,\n",
    "               collocations=False).generate(\" \".join(df[df['sentiment']==\"negative\"]['cleaned_comment']))\n",
    "plt.imshow(wc)\n",
    "plt.title(\"Most used words in negative comments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65610121",
   "metadata": {},
   "source": [
    "### Distribution of Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede7ded3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# Create a pie plot of ratings\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(df['rate'].unique(), labels=df['rate'].unique(), autopct='%1.1f%%', startangle=140, )\n",
    "plt.title('Distribution of Ratings')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b45273",
   "metadata": {},
   "source": [
    "### Number of Comments in Each Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835efd78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract the year from the 'date' column the 'year'\n",
    "years = pd.Series([dt.year for dt in df['date']])\n",
    "\n",
    "# Count the number of rows for each year\n",
    "yearly_counts = years.value_counts().sort_index()\n",
    "\n",
    "# Create a bar plot\n",
    "plt.bar(yearly_counts.index, yearly_counts.values)\n",
    "\n",
    "# Set plot labels and title\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Comments')\n",
    "plt.title('Number of Comments in Each Year')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07feeef5",
   "metadata": {},
   "source": [
    "## Other Visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afd8072",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "ax = merged_df['rate'].value_counts().sort_index().plot(kind=\"bar\",title='Count of Reviews by Stars',figsize=(10, 5))\n",
    "ax.set_xlabel('Review stars') \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cac7ab9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "sns.barplot(data=merged_df, x='rate', y='roberta_pos', ax=axs[0])\n",
    "sns.barplot(data=merged_df, x='rate', y='roberta_neu', ax=axs[1])\n",
    "sns.barplot(data=merged_df, x='rate', y='roberta_neg', ax=axs[2])\n",
    "axs[0].set_title( 'Positive')\n",
    "axs[1].set_title('Neutral')\n",
    "axs[2].set_title('Pogitive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25b8990",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "In conclusion , the sentiment analysis project successfully navigated the challenges posed by the vast volume of MOOC learner feedback. The combination of thorough data preprocessing and advanced NLP techniques paved the way for a robust sentiment analysis model. Through exploratory data analysis, key insights were gleaned, and visualizations provided a nuanced understanding of the dataset. The meticulous cleaning process, feature engineering, and adoption of the RoBERTa model contributed to the creation of an accurate and effective sentiment analysis tool. This project not only streamlined the evaluation of MOOCs but also demonstrated the potential of NLP in extracting valuable insights from unstructured textual data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
